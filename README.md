# ğŸš€ Airflow User Processing Pipeline

A complete data pipeline built with Apache Airflow that demonstrates ETL (Extract, Transform, Load) operations with API integration and PostgreSQL storage.

## ğŸ“‹ Overview

This project showcases a production-ready Airflow DAG that:
- **Extracts** user data from an external API (Marc Lamberti's fakeuser dataset)
- **Transforms** the data into a standardized format
- **Loads** the processed data into PostgreSQL
- **Validates** the data integrity

## ğŸ—ï¸ Architecture

```mermaid
graph TD
    A[Create Table] --> B[API Sensor]
    B --> C[Extract User Data]
    C --> D[Process Data]
    D --> E[Store in PostgreSQL]
    E --> F[Validate Data]
    
    B --> G[External API]
    E --> H[PostgreSQL Database]
```

## ğŸ› ï¸ Features

- âœ… **Modern Airflow 3.0** with TaskFlow API
- âœ… **API Integration** with sensor-based availability checking
- âœ… **PostgreSQL Integration** with proper error handling
- âœ… **Data Validation** and integrity checks
- âœ… **Comprehensive Logging** and monitoring
- âœ… **Resource Management** with automatic cleanup
- âœ… **Retry Logic** and fault tolerance
- âœ… **Production-Ready** code with best practices

## ğŸ“ Project Structure

```
airflow-intro/
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ user_processing.py          # Main DAG file
â”œâ”€â”€ config/                         # Configuration files
â”œâ”€â”€ logs/                          # Airflow logs
â”œâ”€â”€ plugins/                       # Custom plugins
â”œâ”€â”€ docker-compose.yaml            # Docker setup
â””â”€â”€ README.md                      # This file
```

## ğŸš€ Quick Start

### Prerequisites

- Docker and Docker Compose
- Git

### Installation

1. **Clone the repository**
   ```bash
   git clone <your-repo-url>
   cd airflow-intro
   ```

2. **Start the services**
   ```bash
   docker-compose up -d
   ```

3. **Access Airflow UI**
   - URL: http://localhost:8080
   - Username: `admin`
   - Password: Get from logs with `docker-compose logs airflow-apiserver | grep "Password for user"`
   - Example: `Simple auth manager | Password for user 'admin': dftBt3cb6sMkn4df`

4. **Trigger the DAG**
   - Go to the Airflow UI
   - Find the `user_processing` DAG
   - Click the play button to trigger it manually

## ğŸ“Š DAG Details

### Tasks

| Task | Description | Type |
|------|-------------|------|
| `create_table` | Creates PostgreSQL table with proper schema | SQLExecuteQueryOperator |
| `is_api_available` | Sensor that checks API availability | TaskSensor |
| `extract_user` | Extracts and transforms user data | Python Task |
| `process_user` | Creates CSV file for batch processing | Python Task |
| `store_user` | Loads data into PostgreSQL | Python Task |
| `validate_data` | Validates data integrity | Python Task |

### Configuration

- **Schedule**: Daily at midnight
- **Retries**: 2 attempts with 5-minute delay
- **Timeout**: 5 minutes for API sensor
- **Max Active Runs**: 1

## ğŸ”§ Configuration

### Environment Variables

The following environment variables are configured in `docker-compose.yaml`:

```yaml
AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
AIRFLOW__WEBSERVER__AUTHENTICATE: 'false'  # Disabled for development
```

### Database Connection

The DAG uses a PostgreSQL connection with ID `postgres_conn`. The connection details are configured in the Docker Compose setup.

## ğŸ“ˆ Monitoring and Logs

### View Logs

```bash
# View all logs
docker-compose logs

# View specific service logs
docker-compose logs airflow-apiserver
docker-compose logs postgres
```

### Monitor DAG Execution

1. **Airflow UI**: http://localhost:8080
2. **CLI Commands**:
   ```bash
   # List DAGs
   docker-compose exec airflow-apiserver airflow dags list
   
   # Check DAG status
   docker-compose exec airflow-apiserver airflow dags state user_processing
   
   # View task logs
   docker-compose exec airflow-apiserver airflow tasks logs user_processing extract_user 2025-01-01
   ```

## ğŸ§ª Testing

### Test Individual Tasks

```bash
# Test a specific task
docker-compose exec airflow-apiserver airflow tasks test user_processing extract_user 2025-01-01

# Test the entire DAG
docker-compose exec airflow-apiserver airflow dags test user_processing 2025-01-01
```

### Manual DAG Trigger

```bash
# Trigger DAG manually
docker-compose exec airflow-apiserver airflow dags trigger user_processing
```

## ğŸ” Troubleshooting

### Common Issues

1. **DAG not visible in UI**
   ```bash
   docker-compose exec airflow-apiserver airflow dags reserialize
   docker-compose restart airflow-apiserver
   ```

2. **Database connection issues**
   ```bash
   docker-compose logs postgres
   docker-compose restart postgres
   ```

3. **API timeout errors**
   - Check internet connectivity
   - Verify API endpoint is accessible
   - Increase sensor timeout if needed

### Debug Mode

Enable debug logging by setting:
```yaml
AIRFLOW__LOGGING__LOGGING_LEVEL: 'DEBUG'
```

## ğŸ† Best Practices Implemented

- âœ… **Error Handling**: Comprehensive try-catch blocks with specific exception types
- âœ… **Logging**: Structured logging with appropriate levels
- âœ… **Resource Management**: Automatic cleanup of temporary files
- âœ… **Data Validation**: Post-processing validation checks
- âœ… **Documentation**: Inline documentation and docstrings
- âœ… **Configuration**: Centralized configuration management
- âœ… **Retry Logic**: Configurable retry attempts with delays
- âœ… **Security**: Proper parameterized queries to prevent SQL injection

## ğŸ“š Learning Resources

- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [Airflow TaskFlow API](https://airflow.apache.org/docs/apache-airflow/stable/tutorial/taskflow.html)
- [PostgreSQL with Airflow](https://airflow.apache.org/docs/apache-airflow-providers-postgres/stable/index.html)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request


## ğŸ¯ POC Project

This is a **Proof of Concept** project demonstrating:
- Modern Airflow 3.0 TaskFlow API
- API integration with external data sources
- PostgreSQL database operations
- Docker containerization
- Production-ready code structure

**Built by:** Mousami Soni - Data Science Enthusiast specializing in Python, Airflow, Machine Learning, and AI technologies.

## ğŸ™ Acknowledgments

- **Marc Lamberti** - Udemy instructor for the excellent Airflow course and providing the fakeuser dataset
- Apache Airflow community
- PostgreSQL team
- Docker team

---

â­ **Star this repository if you found it helpful!**

